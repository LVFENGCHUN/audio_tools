import io
import os
import uuid
from typing import Any, Dict, List

import folder_paths
import torchaudio
from audiocraft.models import AudioGen
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess

def generate_audiogen_audio(
    descriptions: List[str],
    duration: int = 5,
    model_path: str = "facebook/audiogen-medium",
) -> bytes:
    """
    ä½¿ç”¨ AudioGen æ¨¡å‹ç”ŸæˆéŸ³é¢‘

    å‚æ•°:
        descriptions (list[str]): æ–‡æœ¬æç¤ºåˆ—è¡¨
        duration (int): ç”ŸæˆéŸ³é¢‘çš„æ—¶é•¿ï¼ˆç§’ï¼‰
        model_path (str): é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„

    è¿”å›:
        bytes: wav æ–‡ä»¶çš„äºŒè¿›åˆ¶æ•°æ®
    """
    if not isinstance(descriptions, list) or len(descriptions) == 0:
        raise ValueError("descriptions å¿…é¡»æ˜¯éç©ºåˆ—è¡¨")

    # åŠ è½½æ¨¡å‹
    try:
        model = AudioGen.get_pretrained(model_path)
    except Exception as e:
        raise RuntimeError(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

    # è®¾ç½®ç”Ÿæˆå‚æ•°
    model.set_generation_params(duration=duration)

    # ç”ŸæˆéŸ³é¢‘
    wav = model.generate(descriptions)
    one_wav = wav[0].cpu()

    # ä¿å­˜åˆ° BytesIO
    buffer = io.BytesIO()
    torchaudio.save(buffer, one_wav, model.sample_rate, format="wav")
    buffer.seek(0)

    return buffer.getvalue()


class AudioGenGenerateNode:
    """
    ComfyUI èŠ‚ç‚¹ï¼šä½¿ç”¨ Meta AudioGen æ¨¡å‹æ ¹æ®æ–‡æœ¬æç¤ºç”ŸæˆéŸ³é¢‘ã€‚
    """

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "A calm lo-fi beat with gentle piano and vinyl crackle.", "multiline": True}),
                "duration": ("INT", {"default": 5, "min": 1, "max": 60}),
            }
        }

    RETURN_TYPES = ("AUDIO",)
    RETURN_NAMES = ("audio",)
    FUNCTION = "generate"
    CATEGORY = "audio/generation"

    def _prepare_descriptions(self, prompt: str) -> List[str]:
        # æ”¯æŒå¤šè¡Œæç¤ºï¼Œæ¯è¡Œè§†ä¸ºä¸€ä¸ª prompt
        if not prompt or not prompt.strip():
            raise ValueError("prompt ä¸èƒ½ä¸ºç©º")

        descriptions = [line.strip() for line in prompt.splitlines() if line.strip()]
        if not descriptions:
            raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ promptï¼Œè¯·æä¾›è‡³å°‘ä¸€æ¡æ–‡æœ¬æç¤º")
        return descriptions

    def _bytes_to_audio(self, wav_bytes: bytes) -> Dict[str, Any]:
        """
        å°†ç”Ÿæˆçš„ wav å­—èŠ‚æµè½¬æ¢æˆ ComfyUI AUDIO ç»“æ„ã€‚
        """
        buffer = io.BytesIO(wav_bytes)
        waveform, sample_rate = torchaudio.load(buffer)
        # ComfyUI AUDIO è¦æ±‚å½¢çŠ¶ä¸º [Batch, Channels, Frames]
        waveform = waveform.unsqueeze(0)
        return {
            "waveform": waveform,
            "sample_rate": sample_rate,
        }

    def generate(self, prompt: str, duration: int, model_path: str = "facebook/audiogen-medium"):
        descriptions = self._prepare_descriptions(prompt)
        duration = max(int(duration), 1)

        wav_bytes = generate_audiogen_audio(
            descriptions=descriptions,
            duration=duration,
            model_path=model_path,
        )

        audio = self._bytes_to_audio(wav_bytes)
        return (audio,)


class SenseVoiceTranscribeNode:
    """
    ComfyUI èŠ‚ç‚¹ï¼šä½¿ç”¨ SenseVoiceSmall æ¨¡å‹å°†éŸ³é¢‘è½¬å†™ä¸ºæ–‡æœ¬ã€‚
    """

    _model = None
    _model_config: Dict[str, Any] = {}

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "audio": ("AUDIO",),
            },
            "optional": {
                "device": ("STRING", {"default": "cuda:0"}),
                "language": ("STRING", {"default": "auto"}),
                "use_itn": ("BOOLEAN", {"default": True}),
                "batch_size_s": ("INT", {"default": 60, "min": 1, "max": 600}),
                "merge_vad": ("BOOLEAN", {"default": True}),
                "merge_length_s": ("INT", {"default": 15, "min": 1, "max": 600}),
            },
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("text",)
    FUNCTION = "transcribe"
    CATEGORY = "audio/transcription"

    @classmethod
    def _load_model(cls, model_id: str, device: str):
        config_key = {"model_id": model_id, "device": device}
        if cls._model is not None and cls._model_config == config_key:
            return cls._model

        cls._model = AutoModel(
            model=model_id,
            trust_remote_code=True,
            vad_kwargs={"max_single_segment_time": 30000},
            device=device,
            hub="hf",
        )
        cls._model_config = config_key
        return cls._model

    def _write_temp_audio(self, audio: Dict[str, Any]) -> str:
        """
        ä¿å­˜è¾“å…¥éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œè¿”å›è·¯å¾„ã€‚
        """
        waveform = audio["waveform"]
        sample_rate = audio["sample_rate"]

        if waveform.dim() == 3:
            waveform = waveform[0]

        waveform = waveform.cpu()
        temp_dir = folder_paths.get_temp_directory()
        os.makedirs(temp_dir, exist_ok=True)
        temp_path = os.path.join(temp_dir, f"sensevoice_{uuid.uuid4().hex}.wav")
        torchaudio.save(temp_path, waveform, sample_rate)
        return temp_path

    def transcribe(
        self,
        audio: Dict[str, Any],
        device: str = "cuda:0",
        language: str = "auto",
        use_itn: bool = True,
        batch_size_s: int = 60,
        merge_vad: bool = True,
        merge_length_s: int = 15,
    ):
        temp_path = None
        model_id = os.path.join(folder_paths.models_dir, "SenseVoiceSmall")
        try:
            temp_path = self._write_temp_audio(audio)
            model = self._load_model(model_id, device)
            result = model.generate(
                input=temp_path,
                cache={},
                language=language,
                use_itn=use_itn,
                batch_size_s=batch_size_s,
                merge_vad=merge_vad,
                merge_length_s=merge_length_s,
            )
            text = result[0]["text"] if result else ""
            processed_text = rich_transcription_postprocess(text)
            return (processed_text,)
        finally:
            if temp_path and os.path.exists(temp_path):
                try:
                    os.remove(temp_path)
                except OSError:
                    pass


NODE_CLASS_MAPPINGS = {
    "AudioGenGenerateNode": AudioGenGenerateNode,
    "SenseVoiceTranscribeNode": SenseVoiceTranscribeNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "AudioGenGenerateNode": "ğŸ”Š AudioGen Generate",
    "SenseVoiceTranscribeNode": "ğŸ—£ï¸ SenseVoice Transcribe",
}
